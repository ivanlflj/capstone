{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Analysis project\n",
    "## Data gathering\n",
    "The data was gathered from the Bovespa website in the historical quotes [link](http://www.bmfbovespa.com.br/pt_br/servicos/market-data/historico/mercado-a-vista/cotacoes-historicas/). The instructions to interpret the data are in the same website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# All imports\n",
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Constants\n",
    "RANDOM_SEED = 42\n",
    "DAYS_AHEAD = 5 - 1  #DAYS_AHEAD = 0 is looking 1 day ahead, trying to know today with the data from the past\n",
    "\n",
    "# Data gathering\n",
    "stocks = ['ITSA4 ']\n",
    "paths = ['stock_price\\\\inputs\\\\COTAHIST_A2006.TXT','stock_price\\\\inputs\\\\COTAHIST_A2007.TXT',\n",
    "        'stock_price\\\\inputs\\\\COTAHIST_A2008.TXT','stock_price\\\\inputs\\\\COTAHIST_A2009.TXT']#,\n",
    "        #'stock_price\\\\inputs\\\\COTAHIST_A2010.TXT','stock_price\\\\inputs\\\\COTAHIST_A2011.TXT',\n",
    "        #'stock_price\\\\inputs\\\\COTAHIST_A2012.TXT','stock_price\\\\inputs\\\\COTAHIST_A2013.TXT',\n",
    "        #'stock_price\\\\inputs\\\\COTAHIST_A2014.TXT','stock_price\\\\inputs\\\\COTAHIST_A2015.TXT']\n",
    "df = pd.DataFrame()\n",
    "for stock in stocks:\n",
    "    for path in paths:\n",
    "        file = open(path,'r')\n",
    "        for line in file:\n",
    "            if (line[12:18] == stock):\n",
    "                df = df.append({'year': int(line[2:6]),'month': int(line[6:8]),'day': int(line[8:10]),\n",
    "                                'open': int(line[56:69])/100.,'high': int(line[69:82])/100.,\n",
    "                                'low': int(line[82:95])/100.,'close': int(line[108:121])/100.,\n",
    "                                'volume': int(line[152:170]), 'stock': stocks.index(stock)},ignore_index=True)\n",
    "        file.close\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical analysis\n",
    "The main data has already been gathered. Now it is time to use what is called technical analysis to improve the data we already have.\n",
    "\n",
    "The technical analysis consideres that the price movement of a stock reflects every thing that you need to know about the stock. The following image shows the analysis of a technical analist:\n",
    "\n",
    "![Analysis of a technical analist](http://www.liberatedstocktrader.com/wp-content/uploads/stock-market-analysis-sept-20-2010.jpg)\n",
    "\n",
    "To perform this analysis there is some indicators (calculated from the prizes) that are used for the behaviour prediction. We will use [Moving Averages](http://www.investopedia.com/terms/m/movingaverage.asp) for 5, 8, 21 and 50 periods.\n",
    "\n",
    "It is important to notice that we will only have the data for previous periods and not from our period. So to start we will make every date know about its 50 previous closing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Knowing the past\n",
    "for i in range(1,50 + 1):\n",
    "    df['close'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        df.loc[j,'close'+str(i)] = df.loc[j-i,'close']\n",
    "for i in range(1,50 + 1):\n",
    "    df['low'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        df.loc[j,'low'+str(i)] = df.loc[j-i,'low']\n",
    "for i in range(1,50 + 1):\n",
    "    df['high'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        df.loc[j,'high'+str(i)] = df.loc[j-i,'high']\n",
    "for i in range(1,50 + 1):\n",
    "    df['open'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        df.loc[j,'open'+str(i)] = df.loc[j-i,'open']\n",
    "\n",
    "# Verify if the code worked\n",
    "plt.scatter(df.index.tolist(),df['close'].values,c='c')\n",
    "plt.scatter(df.index.tolist(),df['close50'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the moving averages\n",
    "for i in (5,8,21,50):\n",
    "    df['MA'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        sum = 0\n",
    "        for k in range(1,i+1):\n",
    "            sum += df.loc[j,'close'+str(k)]\n",
    "        df.loc[j,'MA'+str(i)] = sum/i\n",
    "\n",
    "# Verify if the code worked\n",
    "plt.scatter(df.index.tolist(),df['close'].values,c='c')\n",
    "plt.plot(df.index.tolist(),df['MA50'].values,'-',c='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to know which day of the week it is. There is some studies that argue that a stock has a higher probability of moving up depending of the day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['week_day']=-1\n",
    "for i in range(len(df)):\n",
    "    df.loc[i,'week_day'] = datetime.datetime(int(df.loc[i,'year']), int(df.loc[i,'month']), int(df.loc[i,'day'])).weekday()\n",
    "# Just for information Monday to Sunday is 0 to 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volume that we have are also from the last days. In the case of the volume we will gather only the volume for the last 5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,5 + 1):\n",
    "    df['volume'+str(i)] = -1\n",
    "    for j in range(5,len(df)):\n",
    "        df.loc[j,'volume'+str(i)] = df.loc[j-i,'volume']\n",
    "\n",
    "# Verify if the code worked\n",
    "plt.scatter(df.index.tolist(),df['volume'].values,c='c')\n",
    "plt.scatter(df.index.tolist(),df['volume5'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data to use\n",
    "Since the price of the stock varies alot, the important aspect here is the movement relative to the last price. So every price show be divided by the last price (close1) so we have the relative price of the movements until here.\n",
    "We will do the same for the volumes (volume1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[:,'close'] = df.loc[:,'close']/df.loc[:,'close1']\n",
    "df.loc[:,'low'] = df.loc[:,'low']/df.loc[:,'close1']\n",
    "df.loc[:,'high'] = df.loc[:,'high']/df.loc[:,'close1']\n",
    "df.loc[:,'open'] = df.loc[:,'open']/df.loc[:,'close1']\n",
    "\n",
    "for i in range(2,50+1):\n",
    "    df.loc[:,'close'+str(i)] = df.loc[:,'close'+str(i)]/df.loc[:,'close1']\n",
    "    df.loc[:,'low'+str(i)] = df.loc[:,'low'+str(i)]/df.loc[:,'close1']\n",
    "    df.loc[:,'high'+str(i)] = df.loc[:,'high'+str(i)]/df.loc[:,'close1']\n",
    "    df.loc[:,'open'+str(i)] = df.loc[:,'open'+str(i)]/df.loc[:,'close1']\n",
    "    \n",
    "for i in (5,8,21,50):\n",
    "    df.loc[:, 'MA'+str(i)] = df.loc[:, 'MA'+str(i)]/df.loc[:,'close1']\n",
    "\n",
    "df.loc[:,'open1'] = df.loc[:,'open1']/df.loc[:,'close1']\n",
    "df.loc[:,'high1'] = df.loc[:,'high1']/df.loc[:,'close1']\n",
    "df.loc[:,'low1'] = df.loc[:,'low1']/df.loc[:,'close1']\n",
    "df.loc[:,'close1'] = df.loc[:,'close1']/df.loc[:,'close1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same for the volumes (volume1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[:,'volume'] = df.loc[:,'volume']/df.loc[:,'volume1']\n",
    "\n",
    "for i in range(2,5+1):\n",
    "    df.loc[:,'volume'+str(i)] = df.loc[:,'volume'+str(i)]/df.loc[:,'volume1']\n",
    "    \n",
    "df.loc[:,'volume1'] = df.loc[:,'volume1']/df.loc[:,'volume1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "Since the data is now read, we need to erase the 50 first days. They do not have all the indicators that we need for the analysis and it can bring some problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.loc[50:].reset_index()\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the target\n",
    "Until now we have not prepared the target, the target will be a data frame that gives 1 when price close higher than price open, otherwise it returns 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_all = []\n",
    "\n",
    "for i in range(len(df)-DAYS_AHEAD):\n",
    "    is_higher = (1 if (df.loc[i+DAYS_AHEAD,'close']/df.loc[i,'open'] > 1.) else 0)\n",
    "    y_all.extend([is_higher])\n",
    "    \n",
    "df.loc[:len(df)-DAYS_AHEAD-1,'up'] = y_all\n",
    "    \n",
    "df = df.dropna()\n",
    "\n",
    "plt.hist(y_all,bins=3)\n",
    "plt.show()\n",
    "\n",
    "len(y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it is almost a 50% chance for the day to close higher or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "Now that we have the target we can clean our data to start the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = df.drop(['index','close','low','high','open','volume','up','day'],1)\n",
    "\n",
    "X_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "Let's use the data to plot some small studies about the behaviour of the y_all.\n",
    "## Day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(321)\n",
    "plt.hist(df[df['week_day']==0]['up'],bins=3)\n",
    "plt.title('Monday')\n",
    "plt.subplot(322)\n",
    "plt.hist(df[df['week_day']==1]['up'],bins=3)\n",
    "plt.title('Tuesday')\n",
    "plt.subplot(323)\n",
    "plt.hist(df[df['week_day']==2]['up'],bins=3)\n",
    "plt.title('Wednesday')\n",
    "plt.subplot(324)\n",
    "plt.hist(df[df['week_day']==3]['up'],bins=3)\n",
    "plt.title('Thrusday')\n",
    "plt.subplot(325)\n",
    "plt.hist(df[df['week_day']==4]['up'],bins=3)\n",
    "plt.title('Friday')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(431)\n",
    "plt.hist(df[df['month']==1]['up'],bins=3)\n",
    "plt.title('Jan')\n",
    "plt.subplot(432)\n",
    "plt.hist(df[df['month']==2]['up'],bins=3)\n",
    "plt.title('Feb')\n",
    "plt.subplot(433)\n",
    "plt.hist(df[df['month']==3]['up'],bins=3)\n",
    "plt.title('Mar')\n",
    "plt.subplot(434)\n",
    "plt.hist(df[df['month']==4]['up'],bins=3)\n",
    "plt.title('Apr')\n",
    "plt.subplot(435)\n",
    "plt.hist(df[df['month']==5]['up'],bins=3)\n",
    "plt.title('May')\n",
    "plt.subplot(436)\n",
    "plt.hist(df[df['month']==6]['up'],bins=3)\n",
    "plt.title('Jun')\n",
    "plt.subplot(437)\n",
    "plt.hist(df[df['month']==7]['up'],bins=3)\n",
    "plt.title('Jul')\n",
    "plt.subplot(438)\n",
    "plt.hist(df[df['month']==8]['up'],bins=3)\n",
    "plt.title('Aug')\n",
    "plt.subplot(439)\n",
    "plt.hist(df[df['month']==9]['up'],bins=3)\n",
    "plt.title('Sep')\n",
    "plt.subplot(4,3,10)\n",
    "plt.hist(df[df['month']==10]['up'],bins=3)\n",
    "plt.title('Oct')\n",
    "plt.subplot(4,3,11)\n",
    "plt.hist(df[df['month']==11]['up'],bins=3)\n",
    "plt.title('Nov')\n",
    "plt.subplot(4,3,12)\n",
    "plt.hist(df[df['month']==12]['up'],bins=3)\n",
    "plt.title('Dec')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data\n",
    "Here we are splitting the data between train and test. Since it does not look like a stratified data we are use a normal data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all,y_all, test_size = 0.25, random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "We will use the PCA to evaluate the features and the sklearn.feature_selection.SelectKBest to evaluate the features considering the target values. The objective is to reduce it for a more reasonable number. In the moment we have 213 features. We will  reduce the number to components to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pca = PCA()\n",
    "#pca.fit(X_train,y_train)\n",
    "#print pca.explained_variance_ratio_\n",
    "\n",
    "#ica = FastICA(max_iter=20000, tol=0.1, random_state = RANDOM_SEED)\n",
    "#ica.fit(X_train,y_train)\n",
    "\n",
    "skb = SelectKBest(f_classif,k=30)\n",
    "skb.fit(X_train,y_train)\n",
    "#print skb.scores_\n",
    "\n",
    "X_train_reduced = skb.transform(X_train)\n",
    "X_test_reduced = skb.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: First I started with PCA and k=20 in SelectKBest, as mentioned, but the results were not good. Trying to improve I included FastICA and increased the number of variables in the SelectKBest. It improved the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the classifier\n",
    "Since we want to know if the stock will go up in a given day or not it is a classification problem. Considering the amount of data that we have, over 2000, we will use the Support Vector Classifier.\n",
    "\n",
    "For the classifier decision we are using the recommendation of the sklearn website, see image below:\n",
    "\n",
    "![sklearn map](http://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "Together with the classifier we will implement the GridSearchCV and the makescorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = SVC(random_state = RANDOM_SEED)\n",
    "\n",
    "parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'C':[1, 1.5, 3, 5, 10], 'degree':[2,3,4]}\n",
    "\n",
    "precision_scorer = make_scorer(precision_score)\n",
    "\n",
    "clf = GridSearchCV(svc, parameters, scoring = precision_scorer)\n",
    "\n",
    "clf.fit(X_train_reduced, y_train)\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "svc = clf.best_estimator_\n",
    "\n",
    "print(\"The score in the training data was %0.4f.\" % (precision_score(y_train,svc.predict(X_train_reduced))))\n",
    "print(\"The score in the test data was %0.4f.\" % (precision_score(y_test,svc.predict(X_test_reduced))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since SVC is not working lets go to KNeighborsClassifier, as the map suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':[2,4,5,8,16,32,64], 'p':[2, 3], 'leaf_size':[2,5,10,20,30]}\n",
    "\n",
    "clf = GridSearchCV(knc, parameters, scoring = precision_scorer)\n",
    "\n",
    "clf.fit(X_train_reduced, y_train)\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "knc = clf.best_estimator_\n",
    "\n",
    "print(\"The score in the training data was %0.4f.\" % (precision_score(y_train,knc.predict(X_train_reduced))))\n",
    "print(\"The score in the test data was %0.4f.\" % (precision_score(y_test,knc.predict(X_test_reduced))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier also did not work well. Let's try 2 ensemble methods, AdaBoostClassifier and RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(random_state = RANDOM_SEED)\n",
    "\n",
    "parameters = {'algorithm':('SAMME','SAMME.R'), 'n_estimators':[10,30,50,80,120,300,500,800,1200], 'learning_rate':[0.1,0.5,1.0,1.5,2.0]}\n",
    "\n",
    "clf = GridSearchCV(abc, parameters, scoring = precision_scorer)\n",
    "\n",
    "clf.fit(X_train_reduced, y_train)\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "abc = clf.best_estimator_\n",
    "\n",
    "print(\"The score in the training data was %0.4f.\" % (precision_score(y_train,abc.predict(X_train_reduced))))\n",
    "print(\"The score in the test data was %0.4f.\" % (precision_score(y_test,abc.predict(X_test_reduced))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs = -1, random_state = RANDOM_SEED)\n",
    "\n",
    "#parameters = {'n_estimators':[10,30,50,80,120,300,500,800,1200], 'max_depth':[5,8,15,25,30,None],\n",
    "#              'min_samples_split':[1,2,5,10,15,100], 'min_samples_leaf':[1,2,5,10], 'max_features':('sqrt','log2',None)}\n",
    "parameters = {'n_estimators':[50,120,300,500,800,1200], 'max_depth':[5,15,30,None],\n",
    "              'min_samples_split':[1,2,5,15,100], 'min_samples_leaf':[1,4,10], 'max_features':('sqrt','log2',None)}\n",
    "\n",
    "clf = GridSearchCV(rfc, parameters, scoring = precision_scorer)\n",
    "\n",
    "clf.fit(X_train_reduced, y_train)\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "rfc = clf.best_estimator_\n",
    "\n",
    "print(\"The score in the training data was %0.4f.\" % (precision_score(y_train,rfc.predict(X_train_reduced))))\n",
    "print(\"The score in the test data was %0.4f.\" % (precision_score(y_test,rfc.predict(X_test_reduced))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
