{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Analysis project\n",
    "## Data gathering\n",
    "The data was gathered from the Bovespa website in the historical quotes [link](http://www.bmfbovespa.com.br/pt_br/servicos/market-data/historico/mercado-a-vista/cotacoes-historicas/). The instructions to interpret the data are in the same website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# All imports\n",
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Constants\n",
    "RANDOM_SEED = 42\n",
    "DAYS_AHEAD = 1 - 1  #DAYS_AHEAD = 0 is looking 1 day ahead, trying to know today with the data from the past\n",
    "\n",
    "# Data gathering\n",
    "stocks = ['ITSA4 ']#,'VALE5 ','PETR4 '] # Algorithm still need to remove 50 first days of stocks when using more than one.\n",
    "paths = ['stock_price\\\\inputs\\\\COTAHIST_A2006.TXT','stock_price\\\\inputs\\\\COTAHIST_A2007.TXT',\n",
    "        'stock_price\\\\inputs\\\\COTAHIST_A2008.TXT','stock_price\\\\inputs\\\\COTAHIST_A2009.TXT',\n",
    "        'stock_price\\\\inputs\\\\COTAHIST_A2010.TXT','stock_price\\\\inputs\\\\COTAHIST_A2011.TXT',\n",
    "        'stock_price\\\\inputs\\\\COTAHIST_A2012.TXT','stock_price\\\\inputs\\\\COTAHIST_A2013.TXT',\n",
    "        'stock_price\\\\inputs\\\\COTAHIST_A2014.TXT','stock_price\\\\inputs\\\\COTAHIST_A2015.TXT']\n",
    "df = pd.DataFrame()\n",
    "for stock in stocks:\n",
    "    for path in paths:\n",
    "        file = open(path,'r')\n",
    "        for line in file:\n",
    "            if (line[12:18] == stock):\n",
    "                df = df.append({'year': int(line[2:6]),'month': int(line[6:8]),'day': int(line[8:10]),\n",
    "                                'open': int(line[56:69])/100.,'high': int(line[69:82])/100.,\n",
    "                                'low': int(line[82:95])/100.,'close': int(line[108:121])/100.,\n",
    "                                'volume': int(line[152:170]), 'stock': stocks.index(stock)},ignore_index=True)\n",
    "        file.close\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical analysis\n",
    "The main data has already been gathered. Now it is time to use what is called technical analysis to improve the data we already have.\n",
    "\n",
    "The technical analysis consideres that the price movement of a stock reflects every thing that you need to know about the stock. The following image shows the analysis of a technical analist:\n",
    "\n",
    "![Analysis of a technical analist](http://www.liberatedstocktrader.com/wp-content/uploads/stock-market-analysis-sept-20-2010.jpg)\n",
    "\n",
    "To perform this analysis there is some indicators (calculated from the prizes) that are used for the behaviour prediction. We will use [Moving Averages](http://www.investopedia.com/terms/m/movingaverage.asp) for 5, 8, 21 and 50 periods.\n",
    "\n",
    "It is important to notice that we will only have the data for previous periods and not from our period. So to start we will make every date know about its 50 previous closing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Knowing the past\n",
    "for i in range(1,50 + 1):\n",
    "    df['close'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        df.loc[j,'close'+str(i)] = df.loc[j-i,'close']\n",
    "for i in range(1,50 + 1):\n",
    "    df['low'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        df.loc[j,'low'+str(i)] = df.loc[j-i,'low']\n",
    "for i in range(1,50 + 1):\n",
    "    df['high'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        df.loc[j,'high'+str(i)] = df.loc[j-i,'high']\n",
    "for i in range(1,50 + 1):\n",
    "    df['open'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        df.loc[j,'open'+str(i)] = df.loc[j-i,'open']\n",
    "\n",
    "# Verify if the code worked\n",
    "plt.scatter(df.index.tolist(),df['close'].values,c='c')\n",
    "plt.scatter(df.index.tolist(),df['close50'].values)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in (5,8,21,50):\n",
    "    df['MA'+str(i)] = -1\n",
    "    for j in range(50,len(df)):\n",
    "        sum = 0\n",
    "        for k in range(1,i+1):\n",
    "            sum += df.loc[j,'close'+str(k)]\n",
    "        df.loc[j,'MA'+str(i)] = sum/i\n",
    "\n",
    "# Verify if the code worked\n",
    "plt.scatter(df.index.tolist(),df['close'].values,c='c')\n",
    "plt.plot(df.index.tolist(),df['MA50'].values,'-',c='k')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in (2,5,7,14):\n",
    "    df['RSI'+str(i)] = -1\n",
    "    df['AvgGain'+str(i)] = -1\n",
    "    df['AvgLoss'+str(i)] = -1\n",
    "    for j in range(50,51):\n",
    "        sum_gain = 0\n",
    "        sum_loss = 0\n",
    "        for k in range(1,i+1):\n",
    "            change = df.loc[j,'close'+str(k)] - df.loc[j,'close'+str(k+1)]\n",
    "            if change > 0:\n",
    "                sum_gain += change\n",
    "            else:\n",
    "                sum_loss -= change\n",
    "        df.loc[j,'AvgGain'+str(i)] = sum_gain/i\n",
    "        df.loc[j,'AvgLoss'+str(i)] = sum_loss/i\n",
    "        df.loc[j,'RSI'+str(i)] = (100 - 100/(1+(df.loc[j,'AvgGain'+str(i)]/df.loc[j,'AvgLoss'+str(i)])) if df.loc[j,'AvgLoss'+str(i)] != 0 else 0)\n",
    "    for j in range(51,len(df)):\n",
    "        sum_gain = 0\n",
    "        sum_loss = 0\n",
    "        change = df.loc[j,'close1'] - df.loc[j,'close2']\n",
    "        if change > 0:\n",
    "            sum_gain += change\n",
    "        else:\n",
    "            sum_loss -= change\n",
    "        df.loc[j,'AvgGain'+str(i)] = (df.loc[j-1,'AvgGain'+str(i)]*(i-1) + sum_gain)/i\n",
    "        df.loc[j,'AvgLoss'+str(i)] = (df.loc[j-1,'AvgLoss'+str(i)]*(i-1) + sum_loss)/i\n",
    "        df.loc[j,'RSI'+str(i)] = (100 - 100/(1+(df.loc[j,'AvgGain'+str(i)]/df.loc[j,'AvgLoss'+str(i)])) if df.loc[j,'AvgLoss'+str(i)] != 0 else 0)\n",
    "    df = df.drop(['AvgGain'+str(i),'AvgLoss'+str(i)],1)\n",
    "\n",
    "# Verify if the code worked\n",
    "plt.plot(df.index.tolist(),df['RSI14'].values,'-',c='k')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating day of the week\n",
    "\n",
    "We also want to know which day of the week it is. There is some studies that argue that a stock has a higher probability of moving up depending of the day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['week_day']=-1\n",
    "for i in range(len(df)):\n",
    "    df.loc[i,'week_day'] = datetime.datetime(int(df.loc[i,'year']), int(df.loc[i,'month']), int(df.loc[i,'day'])).weekday()\n",
    "# Just for information Monday to Sunday is 0 to 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volume that we have are also from the last days. In the case of the volume we will gather only the volume for the last 5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,5 + 1):\n",
    "    df['volume'+str(i)] = -1\n",
    "    for j in range(5,len(df)):\n",
    "        df.loc[j,'volume'+str(i)] = df.loc[j-i,'volume']\n",
    "\n",
    "# Verify if the code worked\n",
    "plt.scatter(df.index.tolist(),df['volume'].values,c='c')\n",
    "plt.scatter(df.index.tolist(),df['volume5'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the ups in the last 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    df['up'+str(i)] = df['close'+str(i)] - df['open'+str(i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data to use\n",
    "Since the price of the stock varies alot, the important aspect here is the movement relative to the last price. So every price show be divided by the last price (close1) so we have the relative price of the movements until here.\n",
    "We will do the same for the volumes (volume1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[:,'close'] = df.loc[:,'close']/df.loc[:,'close1']\n",
    "df.loc[:,'low'] = df.loc[:,'low']/df.loc[:,'close1']\n",
    "df.loc[:,'high'] = df.loc[:,'high']/df.loc[:,'close1']\n",
    "df.loc[:,'open'] = df.loc[:,'open']/df.loc[:,'close1']\n",
    "\n",
    "for i in range(2,50+1):\n",
    "    df.loc[:,'close'+str(i)] = df.loc[:,'close'+str(i)]/df.loc[:,'close1']\n",
    "    df.loc[:,'low'+str(i)] = df.loc[:,'low'+str(i)]/df.loc[:,'close1']\n",
    "    df.loc[:,'high'+str(i)] = df.loc[:,'high'+str(i)]/df.loc[:,'close1']\n",
    "    df.loc[:,'open'+str(i)] = df.loc[:,'open'+str(i)]/df.loc[:,'close1']\n",
    "    \n",
    "for i in (5,8,21,50):\n",
    "    df.loc[:, 'MA'+str(i)] = df.loc[:, 'MA'+str(i)]/df.loc[:,'close1']\n",
    "\n",
    "for i in range(1,6):\n",
    "    df.loc[:,'up'+str(i)] = df.loc[:,'up'+str(i)]/df.loc[:,'close1']\n",
    "    \n",
    "df.loc[:,'close1'] = df.loc[:,'close1']/df.loc[:,'close1']\n",
    "df.loc[:,'low1'] = df.loc[:,'low1']/df.loc[:,'close1']\n",
    "df.loc[:,'high1'] = df.loc[:,'high1']/df.loc[:,'close1']\n",
    "df.loc[:,'open1'] = df.loc[:,'open1']/df.loc[:,'close1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same for the volumes (volume1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[:,'volume'] = df.loc[:,'volume']/df.loc[:,'volume1']\n",
    "\n",
    "for i in range(2,5+1):\n",
    "    df.loc[:,'volume'+str(i)] = df.loc[:,'volume'+str(i)]/df.loc[:,'volume1']\n",
    "    \n",
    "df.loc[:,'volume1'] = df.loc[:,'volume1']/df.loc[:,'volume1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "Since the data is now read, we need to erase the 50 first days. They do not have all the indicators that we need for the analysis and it can bring some problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.loc[50:].reset_index()\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the target\n",
    "Until now we have not prepared the target, the target will be a data frame that gives how much the close price of the day were in relation of the close1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_all = []\n",
    "\n",
    "for i in range(len(df)-DAYS_AHEAD):\n",
    "    gain = df.loc[i+DAYS_AHEAD,'close']/df.loc[i,'close1']\n",
    "    y_all.extend([gain])\n",
    "    \n",
    "df.loc[:len(df)-DAYS_AHEAD-1,'up'] = y_all\n",
    "    \n",
    "df = df.dropna()\n",
    "\n",
    "plt.hist(y_all)\n",
    "plt.show()\n",
    "\n",
    "len(y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it is almost a 50% chance for the day to close higher or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "Now that we have the target we can clean our data to start the work. Removing index and data from the day, removing objective (up), removing day (since the systems can use it to overfit), removing constants (close1 and volume1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = df.drop(['index','close','low','high','open','volume','up','day','close1','volume1'],1)\n",
    "\n",
    "for i in range(21,50+1):\n",
    "    X_all = X_all.drop(['close'+str(i),'low'+str(i),'high'+str(i),'open'+str(i)],1)\n",
    "\n",
    "X_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "Let's use the data to plot some small studies about the behaviour of the y_all.\n",
    "## Day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(321)\n",
    "plt.hist(df[df['week_day']==0]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Monday')\n",
    "plt.subplot(322)\n",
    "plt.hist(df[df['week_day']==1]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Tuesday')\n",
    "plt.subplot(323)\n",
    "plt.hist(df[df['week_day']==2]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Wednesday')\n",
    "plt.subplot(324)\n",
    "plt.hist(df[df['week_day']==3]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Thrusday')\n",
    "plt.subplot(325)\n",
    "plt.hist(df[df['week_day']==4]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Friday')\n",
    "plt.subplots_adjust(left=0.09, bottom=0.10, right=0.94, top=0.90, wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(431)\n",
    "plt.hist(df[df['month']==1]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Jan')\n",
    "plt.subplot(432)\n",
    "plt.hist(df[df['month']==2]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Feb')\n",
    "plt.subplot(433)\n",
    "plt.hist(df[df['month']==3]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Mar')\n",
    "plt.subplot(434)\n",
    "plt.hist(df[df['month']==4]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Apr')\n",
    "plt.subplot(435)\n",
    "plt.hist(df[df['month']==5]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('May')\n",
    "plt.subplot(436)\n",
    "plt.hist(df[df['month']==6]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Jun')\n",
    "plt.subplot(437)\n",
    "plt.hist(df[df['month']==7]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Jul')\n",
    "plt.subplot(438)\n",
    "plt.hist(df[df['month']==8]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Aug')\n",
    "plt.subplot(439)\n",
    "plt.hist(df[df['month']==9]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Sep')\n",
    "plt.subplot(4,3,10)\n",
    "plt.hist(df[df['month']==10]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Oct')\n",
    "plt.subplot(4,3,11)\n",
    "plt.hist(df[df['month']==11]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Nov')\n",
    "plt.subplot(4,3,12)\n",
    "plt.hist(df[df['month']==12]['up'],range=(0.85,1.25),rwidth=0.8)\n",
    "plt.title('Dec')\n",
    "plt.subplots_adjust(left=0.09, bottom=0.10, right=0.94, top=0.90, wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How last 5 days closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(231)\n",
    "plt.hist(df[df['up']<=1]['up1'],range=(-0.1,0.1),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['up1'],range=(-0.1,0.1),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('up1')\n",
    "plt.subplot(232)\n",
    "plt.hist(df[df['up']<=1]['up2'],range=(-0.1,0.1),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['up2'],range=(-0.1,0.1),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('up2')\n",
    "plt.subplot(233)\n",
    "plt.hist(df[df['up']<=1]['up3'],range=(-0.1,0.1),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['up3'],range=(-0.1,0.1),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('up3')\n",
    "plt.legend()\n",
    "plt.subplot(234)\n",
    "plt.hist(df[df['up']<=1]['up4'],range=(-0.1,0.1),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['up4'],range=(-0.1,0.1),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('up4')\n",
    "plt.subplot(235)\n",
    "plt.hist(df[df['up']<=1]['up5'],range=(-0.1,0.1),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['up5'],range=(-0.1,0.1),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('up5')\n",
    "plt.subplots_adjust(left=0.09, bottom=0.10, right=0.94, top=0.90, wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How last volumes influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(231)\n",
    "plt.hist(df[df['up']<=1]['volume1'],range=(0,10),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['volume1'],range=(0,10),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('volume1')\n",
    "plt.subplot(232)\n",
    "plt.hist(df[df['up']<=1]['volume2'],range=(0,10),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['volume2'],range=(0,10),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('volume2')\n",
    "plt.subplot(233)\n",
    "plt.hist(df[df['up']<=1]['volume3'],range=(0,10),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['volume3'],range=(0,10),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('volume3')\n",
    "plt.legend()\n",
    "plt.subplot(234)\n",
    "plt.hist(df[df['up']<=1]['volume4'],range=(0,10),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['volume4'],range=(0,10),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('volume4')\n",
    "plt.subplot(235)\n",
    "plt.hist(df[df['up']<=1]['volume5'],range=(0,10),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['volume5'],range=(0,10),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('volume5')\n",
    "plt.subplots_adjust(left=0.09, bottom=0.10, right=0.94, top=0.90, wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MA's\n",
    "Some graphs about the Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df[df['up']<=1]['MA5'],range=(0.8,1.25),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['MA5'],range=(0.8,1.25),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('MA5')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df[df['up']<=1]['MA8'],range=(0.7,1.3),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['MA8'],range=(0.7,1.3),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('MA8')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df[df['up']<=1]['MA21'],range=(0.8,1.5),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['MA21'],range=(0.8,1.5),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('MA21')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df[df['up']<=1]['MA50'],range=(0.8,1.8),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['MA50'],range=(0.8,1.8),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('MA50')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df[df['up']<=1]['RSI2'],range=(0,100),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['RSI2'],range=(0,100),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('RSI2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df[df['up']<=1]['RSI5'],range=(0,100),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['RSI5'],range=(0,100),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('RSI5')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df[df['up']<=1]['RSI7'],range=(0,100),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['RSI7'],range=(0,100),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('RSI7')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df[df['up']<=1]['RSI14'],range=(0,100),bins=10,label='Down')\n",
    "plt.hist(df[df['up']>1]['RSI14'],range=(0,100),bins=10,color='r',rwidth=0.5,label='Up')\n",
    "plt.title('RSI14')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data\n",
    "Here we are splitting the data between train and test. Since it does not look like a stratified data we are use a normal data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all,y_all, test_size = 0.25,random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "We will use the PCA to evaluate the features and the sklearn.feature_selection.SelectKBest to evaluate the features considering the target values. The objective is to reduce it for a more reasonable number. In the moment we have 213 features. We will  reduce the number to components to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "ica = FastICA(max_iter=20000, tol=0.001, random_state = RANDOM_SEED)\n",
    "\n",
    "skb = SelectKBest(f_classif)\n",
    "parameters_skb = {'skb__k':[30, 50, 70]}#, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: First I started with PCA and k=20 in SelectKBest, as mentioned, but the results were not good. Trying to improve I included FastICA and increased the number of variables in the SelectKBest. It improved the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the regressor\n",
    "Since we want to know if the stock will go up in a given day or not it is a classification problem. Considering the amount of data that we have, over 2000, we will use the Support Vector Classifier.\n",
    "\n",
    "For the classifier decision we are using the recommendation of the sklearn website, see image below:\n",
    "\n",
    "![sklearn map](http://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "Together with the classifier we will implement the GridSearchCV and the makescorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2_scorer = make_scorer(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(random_state = RANDOM_SEED)\n",
    "\n",
    "parameters_lasso = {'lasso__alpha':[0.1,1,10], 'lasso__normalize':(True,False), 'lasso__fit_intercept':(True,False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enr = ElasticNet(random_state = RANDOM_SEED)\n",
    "\n",
    "parameters_enr = {'enr__alpha':[0.1,1,10], 'enr__normalize':(True,False), 'enr__fit_intercept':(True,False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdg = Ridge(random_state = RANDOM_SEED)\n",
    "\n",
    "parameters_rdg = {'rdg__alpha':[0.01,0.1,1,10,100], 'rdg__normalize':(True,False), 'rdg__fit_intercept':(True,False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "\n",
    "parameters_svr = {'svr__kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'svr__C':[1, 1.5, 3, 5, 10],'svr__degree':[2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(random_state = RANDOM_SEED)\n",
    "\n",
    "parameters_dtr = {'dtr__max_depth':[5,8,15,25,30,None], 'dtr__min_samples_split':[1,2,5,10,15,100],\n",
    "              'dtr__min_samples_leaf':[1,2,5,10], 'dtr__max_features':('sqrt','log2',None)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abr = AdaBoostRegressor(random_state = RANDOM_SEED)\n",
    "\n",
    "parameters_abr = {'abr__n_estimators':[10,30,50,80,120,300,500,800,1200],\n",
    "                  'abr__learning_rate':[0.1,0.5,1.0,1.5,2.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_jobs = -1, random_state = RANDOM_SEED)\n",
    "\n",
    "parameters_rfr = {'rfr__n_estimators':[50,120,300], 'rfr__max_depth':[5,30,None], 'rfr__max_features':('sqrt','log2',None),\n",
    "              'rfr__min_samples_split':[2,5,15], 'rfr__min_samples_leaf':[1,4,10]}\n",
    "#parameters_rfr = {'rfr__n_estimators':[10,30,50,80,120,300,500,800,1200], 'rfr__max_depth':[5,8,15,25,30,None],\n",
    "#              'rfr__min_samples_split':[1,2,5,10,15,100], 'rfr__min_samples_leaf':[1,2,5,10],\n",
    "#              'rfr__max_features':('sqrt','log2',None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To run, using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = [('pca',pca),('skb',skb),('abr', abr)]\n",
    "parameters = {}\n",
    "parameters.update(parameters_skb)\n",
    "parameters.update(parameters_abr)\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=parameters, n_jobs = -1, scoring = r2_scorer, verbose = 1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "pipeline = grid_search.best_estimator_\n",
    "\n",
    "print \"Tuned model has a training precision score of {:.4f}.\".format(r2_score(pipeline.predict(X_train), y_train))\n",
    "print \"Tuned model has a testing precision score of {:.4f}.\".format(r2_score(pipeline.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
